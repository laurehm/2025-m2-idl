{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmJE2a4N8We0"
   },
   "source": [
    "# Introduction to Deep Learning: Cours-2\n",
    "_Adapted from [Dataflowr](https://dataflowr.github.io) by Marc Lelarge_\n",
    "\n",
    "## System setup\n",
    "\n",
    "Import the required packages, check the current version of PyTorch, and check that GPU is available (on Colab you may need to change the runtime first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOgNQwiv8We1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"{torch.__version__=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vURcLof_8We8"
   },
   "source": [
    "## Back to Basics: Tensors\n",
    "\n",
    "Tensors are used to encode the signal to process, but also the internal states and parameters of models.\n",
    "\n",
    "**Manipulating data through this constrained structure allows to use CPUs and GPUs at peak performance.**\n",
    "\n",
    "In PyTorch, a Tensor is similar to numpy NDArray: a multidimensional array containing data **of the same type**.\n",
    "\n",
    "### Tensor Construction Functions\n",
    "\n",
    "PyTorch provides several functions to create tensors. Let's start with the most common ones for 1D arrays.\n",
    "\n",
    "#### Creating tensors filled with constant values\n",
    "\n",
    "The most basic constructors create tensors filled with zeros, ones, or uninitialized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference tensor\n",
    "print(torch.zeros(10))\n",
    "print(torch.ones(12))\n",
    "print(torch.empty(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multidimensional tensors\n",
    "\n",
    "All these functions work with higher dimensions too. Just pass a tuple of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D tensor (matrix)\n",
    "matrix = torch.zeros(3, 4)\n",
    "print(f\"2D zeros:\\n{matrix}\")\n",
    "print(f\"shape: {matrix.shape}\")\n",
    "\n",
    "# 3D tensor\n",
    "tensor_3d = torch.ones(2, 3, 4)\n",
    "print(f\"\\n3D ones shape: {tensor_3d.shape}\")\n",
    "\n",
    "# 4D tensor (typical for batches of images: batch, channels, height, width)\n",
    "batch_images = torch.randn(8, 3, 32, 32)\n",
    "print(f\"4D batch of images shape: {batch_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating random tensors\n",
    "\n",
    "Random tensors are essential for initializing neural network weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random values from uniform distribution [0, 1)\n",
    "rand_uniform = torch.rand(5)\n",
    "print(f\"rand (uniform [0,1)): {rand_uniform}\")\n",
    "\n",
    "# Random values from standard normal distribution (mean=0, std=1)\n",
    "rand_normal = torch.randn(5)\n",
    "print(f\"randn (normal N(0,1)): {rand_normal}\")\n",
    "\n",
    "# Random integers\n",
    "rand_int = torch.randint(0, 10, (5,))  # integers in [0, 10)\n",
    "print(f\"randint(0, 10): {rand_int}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating tensors from data\n",
    "\n",
    "You can also create tensors directly from Python lists or NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a Python list\n",
    "from_list = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"from list: {from_list}\")\n",
    "\n",
    "# From a NumPy array\n",
    "import numpy as np\n",
    "np_array = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "from_numpy = torch.from_numpy(np_array)\n",
    "print(f\"from numpy: {from_numpy}, dtype: {from_numpy.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating tensors with ranges\n",
    "\n",
    "Similar to `numpy.arange()` and `numpy.linspace()`, PyTorch provides `torch.arange()` and `torch.linspace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of values\n",
    "range_tensor = torch.arange(0, 10)\n",
    "print(f\"arange(0, 10): {range_tensor}\")\n",
    "\n",
    "# With a step\n",
    "range_step = torch.arange(0, 10, 2)\n",
    "print(f\"arange(0, 10, 2): {range_step}\")\n",
    "\n",
    "# Linearly spaced values\n",
    "linspace_tensor = torch.linspace(0, 1, 5)\n",
    "print(f\"linspace(0, 1, 5): {linspace_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying data type\n",
    "\n",
    "You can specify the data type (dtype) when creating tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer tensor\n",
    "int_tensor = torch.zeros(5, dtype=torch.int32)\n",
    "print(f\"int32 tensor: {int_tensor}, dtype: {int_tensor.dtype}\")\n",
    "\n",
    "# Long (64-bit integer) tensor\n",
    "long_tensor = torch.ones(5, dtype=torch.long)\n",
    "print(f\"long tensor: {long_tensor}, dtype: {long_tensor.dtype}\")\n",
    "\n",
    "# Float32 (default for float operations)\n",
    "float_tensor = torch.ones(5, dtype=torch.float32)\n",
    "print(f\"float32 tensor: {float_tensor}, dtype: {float_tensor.dtype}\")\n",
    "\n",
    "# Float64 (double precision)\n",
    "double_tensor = torch.zeros(5, dtype=torch.float64)\n",
    "print(f\"float64 tensor: {double_tensor}, dtype: {double_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** `torch.empty()` doesn't initialize the values - it's faster but contains arbitrary data. Use it only when you're going to fill all values immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1D tensor of zeros\n",
    "zeros = torch.zeros(5)\n",
    "print(f\"zeros: {zeros}\")\n",
    "print(f\"dtype: {zeros.dtype}, shape: {zeros.shape}\")\n",
    "\n",
    "# Create a 1D tensor of ones\n",
    "ones = torch.ones(5)\n",
    "print(f\"\\nones: {ones}\")\n",
    "print(f\"dtype: {ones.dtype}, shape: {ones.shape}\")\n",
    "\n",
    "# Create an uninitialized tensor (contains whatever was in memory)\n",
    "empty = torch.empty(5)\n",
    "print(f\"\\nempty: {empty}\")\n",
    "print(f\"dtype: {empty.dtype}, shape: {empty.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Slicing\n",
    "\n",
    "PyTorch tensors support NumPy-style indexing and slicing. You can extract elements, rows, columns, or multi-dimensional slices from tensors.\n",
    "\n",
    "#### Basic indexing for 1D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1D tensor\n",
    "x = torch.arange(10)\n",
    "print(f\"Original tensor: {x}\")\n",
    " \n",
    "# Access single element\n",
    "print(f\"x[0]: {x[0]}\")\n",
    "print(f\"x[5]: {x[5]}\")\n",
    "print(f\"x[-1] (last element): {x[-1]}\")\n",
    "\n",
    "# Extract scalar value with .item()\n",
    "print(f\"{x[5].item()=} ({type(x[5].item())})\")\n",
    "print(f\"{x[5].item()=} ({type(x[5])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing 1D tensors\n",
    "\n",
    "Slicing uses the syntax `[start:stop:step]`. Like Python lists, the stop index is exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(10)\n",
    "print(f\"Original: {x}\")\n",
    "\n",
    "# Basic slicing\n",
    "print(f\"x[2:5]: {x[2:5]}\")        # Elements from index 2 to 4\n",
    "print(f\"x[:5]: {x[:5]}\")          # First 5 elements\n",
    "print(f\"x[5:]: {x[5:]}\")          # From index 5 to end\n",
    "print(f\"x[:]: {x[:]}\")            # All elements (creates a view)\n",
    "\n",
    "# Slicing with step\n",
    "print(f\"x[::2]: {x[::2]}\")        # Every other element\n",
    "print(f\"x[1::2]: {x[1::2]}\")      # Every other element, starting at 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing 2D tensors (matrices)\n",
    "\n",
    "For multi-dimensional tensors, use comma-separated indices for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D tensor\n",
    "matrix = torch.arange(12).reshape(3, 4)\n",
    "print(f\"Original matrix:\\n{matrix}\")\n",
    "\n",
    "# Access single element\n",
    "print(f\"\\nmatrix[0, 0]: {matrix[0, 0]}\")  # First row, first column\n",
    "print(f\"matrix[1, 2]: {matrix[1, 2]}\")    # Second row, third column\n",
    "print(f\"matrix[-1, -1]: {matrix[-1, -1]}\")  # Last row, last column\n",
    "\n",
    "# Access entire row\n",
    "print(f\"\\nmatrix[0]: {matrix[0]}\")        # First row (equivalent to matrix[0, :])\n",
    "print(f\"matrix[1, :]: {matrix[1, :]}\")    # Second row (explicit)\n",
    "\n",
    "# Access entire column\n",
    "print(f\"\\nmatrix[:, 0]: {matrix[:, 0]}\")  # First column\n",
    "print(f\"matrix[:, 2]: {matrix[:, 2]}\")    # Third column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing 2D tensors\n",
    "\n",
    "You can slice along multiple dimensions simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.arange(12).reshape(3, 4)\n",
    "print(f\"Original matrix:\\n{matrix}\")\n",
    "\n",
    "# Slice rows and columns\n",
    "print(f\"\\nmatrix[0:2, :]: First 2 rows\\n{matrix[0:2, :]}\")\n",
    "print(f\"\\nmatrix[:, 1:3]: Columns 1 and 2\\n{matrix[:, 1:3]}\")\n",
    "print(f\"\\nmatrix[1:, 2:]: Submatrix from row 1, col 2\\n{matrix[1:, 2:]}\")\n",
    "\n",
    "# Combining slicing with steps\n",
    "print(f\"\\nmatrix[::2, ::2]: Every other row and column\\n{matrix[::2, ::2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced indexing with lists and tensors\n",
    "\n",
    "You can use lists or tensors to select specific indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(10)\n",
    "print(f\"Original: {x}\")\n",
    "\n",
    "# Index with a list\n",
    "indices = [0, 2, 4, 6]\n",
    "print(f\"x[indices]: {x[indices]}\")\n",
    "\n",
    "# Index with a tensor\n",
    "indices_tensor = torch.tensor([1, 3, 5, 7])\n",
    "print(f\"x[indices_tensor]: {x[indices_tensor]}\")\n",
    "\n",
    "# Boolean indexing (masking)\n",
    "mask = x > 5\n",
    "print(f\"\\nBoolean mask (x > 5): {mask}\")\n",
    "print(f\"x[mask]: {x[mask]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying values through slicing\n",
    "\n",
    "Slicing creates a **view** of the original tensor. Modifying the slice modifies the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(10)\n",
    "print(f\"Original: {x}\")\n",
    "\n",
    "# Modify a single element\n",
    "x[5] = 100\n",
    "print(f\"After x[5] = 100: {x}\")\n",
    "\n",
    "# Modify a slice\n",
    "x[2:5] = torch.tensor([20, 30, 40])\n",
    "print(f\"After x[2:5] = [20, 30, 40]: {x}\")\n",
    "\n",
    "# Set all elements in a slice to the same value\n",
    "x[7:] = 0\n",
    "print(f\"After x[7:] = 0: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `...` (ellipsis) for flexible slicing\n",
    "\n",
    "The ellipsis `...` represents \"all remaining dimensions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 3, 32, 32)  # (batch, channels, height, width)\n",
    "\n",
    "# These are equivalent:\n",
    "print(f\"x[0, :, :, :].shape: {x[0, :, :, :].shape}\")\n",
    "print(f\"x[0, ...].shape: {x[0, ...].shape}\")\n",
    "print(f\"x[0].shape: {x[0].shape}\")\n",
    "\n",
    "# Extract last column from all dimensions\n",
    "print(f\"\\nx[..., -1].shape: {x[..., -1].shape}\")  # Last width dimension\n",
    "print(f\"x[:, :, :, -1].shape: {x[:, :, :, -1].shape}\")  # Equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridge to numpy\n",
    "\n",
    "Let's start with a random 3x5 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlY-hwAY8WfB"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3,5)\n",
    "print(x)\n",
    "print(f\"{x.shape=}, {x.size()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert a Torch tensor to numpy that can be used with other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1cDkoT98WfM"
   },
   "outputs": [],
   "source": [
    "y = x.numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Careful with types!\n",
    "\n",
    "It is also possible to cast an existing tensor to a different type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cg-kloHeB_hR"
   },
   "outputs": [],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a.dtype)\n",
    "print(b.dtype)\n",
    "\n",
    "c = b.long()\n",
    "print(c.dtype, c)\n",
    "print(b.dtype, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the cast is automatic..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5nYMEcM8WfS"
   },
   "outputs": [],
   "source": [
    "xr = torch.randn(3, 5)\n",
    "print(xr.dtype, xr)\n",
    "\n",
    "resb = xr + b\n",
    "print(resb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resc = xr + c\n",
    "resc\n",
    "print(resc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuZ0-dswB_hf"
   },
   "source": [
    "But be careful, with types and what you see in the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Jdin_2zB_hg"
   },
   "outputs": [],
   "source": [
    "resb == resc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rn7Xp9dpB_hk"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "print(resb[0,-1])\n",
    "print(resc[0,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkYkbUJNB_hr"
   },
   "outputs": [],
   "source": [
    "resc[0,-1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCBKNjLdB_hu"
   },
   "outputs": [],
   "source": [
    "xr[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wGdO-oaRB_hw"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kt-CZCaZ8WgO"
   },
   "source": [
    "### Broadcasting\n",
    "\n",
    "(from https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
    "\n",
    "Broadcasting automagically expands dimensions by replicating coefficients, when it is necessary to perform operations.\n",
    "\n",
    "\n",
    "**Broadcasting Rule:**\n",
    "\n",
    "1. If one of the tensors has fewer dimensions than the other, it is reshaped by adding as many dimensions of size 1 as necessary in the front; then\n",
    "2. for every mismatch, if one of the two tensor is of size one, it is expanded along this axis by replicating coefficients.\n",
    "\n",
    "If there is a tensor size mismatch for one of the dimension and neither of them is one, the operation fails.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "When one tensor has a dimension of size 0 (empty tensor):\n",
    "\n",
    "![broadcast_1x0](imgs/broadcast_1x0.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.Tensor([1, 2, 3]) * 2)\n",
    "print(torch.Tensor([1, 2, 3]) * torch.Tensor([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2D tensor broadcasted with a 1D tensor:\n",
    "\n",
    "![broadcast_2x1](imgs/broadcast_2x1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0, 40, 10).unsqueeze(1).repeat(1, 3)\n",
    "b = torch.arange(1, 4, 1)\n",
    "\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When broadcasting fails due to incompatible shapes:\n",
    "\n",
    "![broadcast_mismatch](imgs/broadcast_mismatch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.arange(1, 5, 1)\n",
    "\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When both tensors have at least one dimension of size 1, both are reshaped:\n",
    "\n",
    "![broadcast_1x1](imgs/broadcast_1x1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvB3V_ek8WgP"
   },
   "outputs": [],
   "source": [
    "a = torch.arange(0, 40, 10).unsqueeze(1)\n",
    "b = torch.arange(0, 4, 1)\n",
    "\n",
    "print(f\"{a=}, {a.shape}\")\n",
    "print(f\"{b=}, {b.shape}\")\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gq32MIeZB_h3"
   },
   "source": [
    "### In-place modification\n",
    "\n",
    "If you care a lot about memory consumption, you can also use in-place mutation of your tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-V4Qvh2JB_h4"
   },
   "outputs": [],
   "source": [
    "print(f\"{x=}\")\n",
    "print(f\"{xr=}\")\n",
    "\n",
    "print(f\"{x+xr=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jk8j_AhL8Wfa"
   },
   "outputs": [],
   "source": [
    "x.add_(xr)\n",
    "print(f\"{x=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmB6aFc08Wfc"
   },
   "source": [
    "Any operation that mutates a tensor in-place is post-fixed with an ```_```\n",
    "\n",
    "For example: `x.fill_(y)` (fill with value y), `x.t_()` (transpose), will change ```x```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rzb4jk-d8Wfd"
   },
   "outputs": [],
   "source": [
    "print(f\"{x.t()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNXvqa_38Wff"
   },
   "outputs": [],
   "source": [
    "x.t_()\n",
    "print(f\"{x=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zO4O1rJD8Wfi"
   },
   "source": [
    "### Shared memory\n",
    "\n",
    "Careful (again) changing the torch tensor modify the numpy array and vice-versa (see the PyTorch documentation [here](https://pytorch.org/docs/stable/torch.html#torch.from_numpy)):\n",
    "The returned tensor by `torch.from_numpy` and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYOR2MzI8Wfj"
   },
   "outputs": [],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZP8DJXaC8Wfl"
   },
   "outputs": [],
   "source": [
    "a[2] = 0\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ixqe4FEB_iL"
   },
   "outputs": [],
   "source": [
    "b[3] = 5\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahC2FkEGB_iN"
   },
   "source": [
    "### Cuda\n",
    "\n",
    "Now, compared to numpy, one key advantage of PyTorch, is that we can use them on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Aq_IjCa8Wfo"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available() or torch.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZ9T7v3L8Wfq"
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tensors live on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQv3WhHn8Wft"
   },
   "outputs": [],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to explicitely transfer them to GPU using the `.to(device)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKY8kHv_8Wfw"
   },
   "outputs": [],
   "source": [
    "# Only run with a GPU runtime\n",
    "y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "x = x.to(device)                       # or just use strings `.to(\"cuda\")` or `.to(\"mps\")`\n",
    "z = x + y\n",
    "print(z,z.type())\n",
    "print(z.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor with only one value (scalar) can be converted to regular Python values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1A7Q5VYK8Wfx"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(1)\n",
    "x = x.to(device)\n",
    "\n",
    "print(f\"{x.device=}\")\n",
    "print(x.cpu().numpy())\n",
    "print(x.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ppop1eqWB_if"
   },
   "source": [
    "# Simple interfaces to standard image data-bases\n",
    "\n",
    "\n",
    "PyTorch already offers interfaces to the most popular datasets.\n",
    "Let's check the [CIFAR10](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.CIFAR10) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7O6lDC88Wf1"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "cifar = torchvision.datasets.CIFAR10(data_dir, train = True, download = True)\n",
    "cifar.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfIsAgwGB_ih"
   },
   "source": [
    "Unfortunately, sometimes the data is not packaged in the expected format.\n",
    "Here we need (batchs, channels, imgs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(cifar.data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to permute the dimensions.\n",
    "\n",
    "Doc: [`permute`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37KuS3m-B_ii"
   },
   "outputs": [],
   "source": [
    "x = torch.from_numpy(cifar.data).permute(0,3,1,2).float()\n",
    "x = x / 255\n",
    "print(x.type(), x.size(), x.min().item(), x.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfrAC1GaB_ik"
   },
   "source": [
    "Now let's check the first 48 images. \n",
    "\n",
    "Doc: [`narrow(input, dim, start, length)`](https://pytorch.org/docs/stable/torch.html#torch.narrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZUzzXJD8Wf3"
   },
   "outputs": [],
   "source": [
    "# Narrows to the first images, converts to float\n",
    "x = torch.narrow(x, 0, 0, 48)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVT7H5jS8Wf8"
   },
   "outputs": [],
   "source": [
    "# Showing images\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "show(torchvision.utils.make_grid(x, nrow = 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, 1, ...] = 0 # kill green channel\n",
    "x[:, 2, ...] = 0 # kill blue channel\n",
    "show(torchvision.utils.make_grid(x, nrow = 12))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "02_basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "2025-m2-idl (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
