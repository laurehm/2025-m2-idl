{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP: Transfer Learning for MNIST Classification\n",
    "\n",
    "Here you will learn how to use transfer learning to adapt a pre-trained CNN for a new classification task. We will use a small but performant network pre-trained on ImageNet (1000 classes) and adapt it to classify MNIST handwritten digits (10 classes).\n",
    "\n",
    "**Learning objectives:**\n",
    "- Understand transfer learning concepts\n",
    "- Load and prepare the MNIST dataset\n",
    "- Use a pre-trained model and modify its classification head\n",
    "- Train only the new layers while freezing pre-trained weights\n",
    "- Evaluate model performance on a validation set\n",
    "\n",
    "## System setup\n",
    "\n",
    "Import the required packages and check PyTorch version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "import time\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"{torch.__version__=}\")\n",
    "print(f\"Using {device=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the MNIST dataset\n",
    "\n",
    "MNIST is a classic dataset of 28x28 grayscale images of handwritten digits (0-9). It contains:\n",
    "- 60,000 training images\n",
    "- 10,000 test images\n",
    "\n",
    "PyTorch will automatically download the dataset for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "**Important:** Pre-trained models expect input in a specific format:\n",
    "- Images must be resized to 224x224 (ImageNet standard)\n",
    "- Images must have 3 color channels (RGB)\n",
    "- Images must be normalized with ImageNet statistics\n",
    "\n",
    "Since MNIST images are:\n",
    "- 28x28 pixels (too small)\n",
    "- Grayscale (1 channel instead of 3)\n",
    "\n",
    "We need to transform them appropriately.\n",
    "\n",
    "**TODO 1:** Complete the transform pipeline below to:\n",
    "1. Resize MNIST images to 224x224\n",
    "2. Convert grayscale to RGB (3 channels)\n",
    "3. Convert to tensor\n",
    "4. Normalize with ImageNet statistics\n",
    "\n",
    "Check the doc of the following transforms: \n",
    "- [transforms.Resize](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.Resize.html)\n",
    "- [transforms.Grayscale](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.Grayscale.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization statistics\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# TODO 1: Complete this transform pipeline\n",
    "mnist_transform = transforms.Compose([\n",
    "    #TODO\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 2:** Load the MNIST dataset for training and testing using `datasets.MNIST`.\n",
    "\n",
    "Hints:\n",
    "- Set `train=True` for training set, `train=False` for test set\n",
    "- Set `download=True` to download the dataset\n",
    "- Use the `mnist_transform` we defined above\n",
    "\n",
    "MNIST is so popular, the dataset is already available in torchvision: check the doc for [datasets.MNIST](https://docs.pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Load MNIST datasets\n",
    "train_dataset = {} #TODO\n",
    "test_dataset = {} #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset sizes\n",
    "dset_sizes = {'train': len(train_dataset), 'test': len(test_dataset)}\n",
    "print(f\"Training set size: {dset_sizes['train']}\")\n",
    "print(f\"Test set size: {dset_sizes['test']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the MNIST class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classes = train_dataset.classes\n",
    "print(f\"MNIST classes: {mnist_classes}\")\n",
    "print(f\"Number of classes: {len(mnist_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 3:** Create DataLoaders for training and testing.\n",
    "\n",
    "Hints:\n",
    "- Use batch_size=64 for training\n",
    "- Use batch_size=100 for testing\n",
    "- Shuffle training data but not test data\n",
    "- Set num_workers=2 (lower than dogs/cats example for CPU training)\n",
    "\n",
    "Check the doc for [torch.utils.data.DataLoader](https://docs.pytorch.org/docs/stable/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3: Create DataLoaders\n",
    "train_loader = [] #TODO\n",
    "test_loader = [] #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some examples from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, labels = next(iter(train_loader))\n",
    "\n",
    "print(f\"Batch shape: {inputs.shape}\")\n",
    "print(f\"Labels: {labels[:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image from tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = np.clip(std * inp + mean, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Make a grid from batch\n",
    "n_images = 8\n",
    "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
    "imshow(out, title=[str(x.item()) for x in labels[0:n_images]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pre-trained model: MobileNetV3 \n",
    "\n",
    "We will use [**MobileNetV3-small**](https://huggingface.co/qualcomm/MobileNet-v3-Small), a small and efficient CNN designed for mobile devices. Despite its small size (~2.5M parameters), it achieves relatively good performance on ImageNet for its size.\n",
    "\n",
    "Let's load the pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "model = models.mobilenet_v3_small(weights='DEFAULT')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the structure of MobileNetV2:\n",
    "- `features`: Convolutional layers for feature extraction\n",
    "- `classifier`: Final classification layer(s)\n",
    "\n",
    "The classifier outputs 1000 classes (ImageNet). We need to modify it for 10 classes (MNIST digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassifier structure:\")\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the classification head\n",
    "\n",
    "**Transfer learning strategy:**\n",
    "1. Freeze all pre-trained weights (no gradient computation)\n",
    "2. Replace the final layer to output 10 classes instead of 1000\n",
    "3. Train only the new layer\n",
    "\n",
    "**TODO 4:** Complete the code below to:\n",
    "1. Freeze all parameters in the model\n",
    "2. Replace the final linear layer with a new one for 10 classes\n",
    "\n",
    "Hints:\n",
    "- The classifier is a Sequential with Dropout and Linear layers\n",
    "- The Linear layer is at index 3: `model.classifier[3]`\n",
    "- The input features to this layer is 1024 (check the print above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4: Freeze all parameters and replace final layer\n",
    "\n",
    "# Freeze all parameters\n",
    "#TODO\n",
    "\n",
    "# Replace the final layer: Linear(1024, 1000) -> Linear(1280, 10)\n",
    "#TODO\n",
    "\n",
    "print(\"\\nModified classifier:\")\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device (GPU/MPS/CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Verify: count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How many parameters do we need to train?\n",
    "\n",
    "**Answer:** The final linear layer has 1024 input features and 10 output classes, so:\n",
    "- Weights: 1024 Ã— 10 = 10,240\n",
    "- Bias: 10\n",
    "- **Total: 10,250 parameters**\n",
    "\n",
    "This is very small compared to the full model (~2.5M parameters)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the new layer\n",
    "\n",
    "### Creating loss function and optimizer\n",
    "\n",
    "**TODO 5:** Create the loss function and optimizer.\n",
    "\n",
    "Hints:\n",
    "- Use CrossEntropyLoss for multi-class classification\n",
    "- Use SGD optimizer with learning_rate=0.01 and momentum=0.9\n",
    "- Only pass the parameters of the new layer to the optimizer: `model.classifier[3].parameters()`\n",
    "\n",
    "Check the doc for:\n",
    "- [nn.CrossEntropyLoss](https://docs.pytorch.org/docs/stable/generated/torch.nn.modules.loss.CrossEntropyLoss.html)\n",
    "- [torch.optim.SGD](https://docs.pytorch.org/docs/stable/generated/torch.optim.SGD.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5: Define loss and optimizer\n",
    "criterion = None #TODO\n",
    "optimizer = None #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Now let's train the model. The training function performs:\n",
    "1. Forward pass: compute predictions\n",
    "2. Loss computation: compare predictions with true labels\n",
    "3. Backward pass: compute gradients\n",
    "4. Optimizer step: update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def train_model(model, dataloader, size, epochs=1, optimizer=None):\n",
    "    \"\"\"Train the model for given number of epochs.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, classes in tqdm(dataloader):\n",
    "            inputs, classes = inputs.to(device), classes.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, classes)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_loss += loss.data.item()\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "        \n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects.data.item() / size\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 6:** Train the model for 3 epochs.\n",
    "\n",
    "Note: This should run on CPU in a reasonable time, but still need a few minutes per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TODO 6: Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now let's test our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, size):\n",
    "    \"\"\"Evaluate the model on test data.\"\"\"\n",
    "    model.eval()\n",
    "    predictions = np.zeros(size)\n",
    "    all_classes = np.zeros(size)\n",
    "    all_proba = np.zeros((size, 10))\n",
    "    \n",
    "    i = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, classes in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, classes)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.data.item()\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "            \n",
    "            predictions[i:i+len(classes)] = preds.to('cpu').numpy()\n",
    "            all_classes[i:i+len(classes)] = classes.to('cpu').numpy()\n",
    "            all_proba[i:i+len(classes), :] = nn.functional.softmax(outputs, dim=1).to('cpu').numpy()\n",
    "            i += len(classes)\n",
    "    \n",
    "    epoch_loss = running_loss / size\n",
    "    epoch_acc = running_corrects.data.item() / size\n",
    "    print(f'Test Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "    return predictions, all_proba, all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions, all_proba, all_classes = test_model(model, test_loader, size=dset_sizes['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "\n",
    "Let's analyze the model's predictions to understand its behavior.\n",
    "\n",
    "### 1. Correct predictions\n",
    "\n",
    "First, let's look at some correct predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy\n",
    "correct = [] #TODO\n",
    "accuracy = len(correct) / dset_sizes['test']\n",
    "print(f\"Test accuracy: {accuracy:.4f} ({len(correct)}/{dset_sizes['test']} correct)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some correct predictions\n",
    "from numpy.random import permutation\n",
    "\n",
    "n_view = 16\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, x in enumerate(permutation(correct)[:n_view]):\n",
    "    img, label = test_dataset[x]\n",
    "    img_np = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_np = np.clip(std * img_np + mean, 0, 1)\n",
    "    \n",
    "    axes[idx].imshow(img_np)\n",
    "    axes[idx].set_title(f'True: {int(all_classes[x])}\\nPred: {int(predictions[x])}\\nConf: {all_proba[x, int(predictions[x])]:.2f}')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Incorrect predictions\n",
    "\n",
    "Let's examine where the model fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize incorrect predictions\n",
    "incorrect = [] #TODO\n",
    "print(f\"Number of incorrect predictions: {len(incorrect)}\")\n",
    "\n",
    "if len(incorrect) > 0:\n",
    "    n_view = min(16, len(incorrect))\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, x in enumerate(permutation(incorrect)[:n_view]):\n",
    "        img, label = test_dataset[x]\n",
    "        img_np = img.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img_np = np.clip(std * img_np + mean, 0, 1)\n",
    "        \n",
    "        axes[idx].imshow(img_np)\n",
    "        axes[idx].set_title(f'True: {int(all_classes[x])}\\nPred: {int(predictions[x])}\\nConf: {all_proba[x, int(predictions[x])]:.2f}', \n",
    "                           color='red')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_view, 16):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Most confident predictions\n",
    "\n",
    "Let's look at predictions where the model is most confident:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most confident predictions (highest probability)\n",
    "confidences = [] #TODO\n",
    "most_confident_idx = [] #TODO\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, x in enumerate(most_confident_idx):\n",
    "    img, label = test_dataset[x]\n",
    "    img_np = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_np = np.clip(std * img_np + mean, 0, 1)\n",
    "    \n",
    "    axes[idx].imshow(img_np)\n",
    "    is_correct = predictions[x] == all_classes[x]\n",
    "    color = 'green' if is_correct else 'red'\n",
    "    axes[idx].set_title(f'True: {int(all_classes[x])}\\nPred: {int(predictions[x])}\\nConf: {confidences[x]:.4f}', \n",
    "                       color=color)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Most uncertain predictions\n",
    "\n",
    "Finally, let's examine cases where the model is uncertain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most uncertain predictions (probability closest to uniform)\n",
    "uncertainty = [] #TODO  # Lower confidence = higher uncertainty\n",
    "most_uncertain_idx = [] #TODO\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, x in enumerate(most_uncertain_idx):\n",
    "    img, label = test_dataset[x]\n",
    "    img_np = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_np = np.clip(std * img_np + mean, 0, 1)\n",
    "    \n",
    "    axes[idx].imshow(img_np)\n",
    "    is_correct = predictions[x] == all_classes[x]\n",
    "    color = 'green' if is_correct else 'red'\n",
    "    \n",
    "    # Show top 2 predictions\n",
    "    top2_idx = np.argsort(-all_proba[x])[:2]\n",
    "    top2_prob = all_proba[x][top2_idx]\n",
    "    \n",
    "    axes[idx].set_title(f'True: {int(all_classes[x])}\\nTop: {top2_idx[0]}({top2_prob[0]:.2f}), {top2_idx[1]}({top2_prob[1]:.2f})', \n",
    "                       color=color, fontsize=9)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Confusion matrix\n",
    "\n",
    "A confusion matrix helps us understand which digits are confused with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_classes, predictions)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Per-class accuracy\n",
    "\n",
    "Let's see how well the model performs on each digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy\n",
    "for digit in range(10):\n",
    "    digit_mask = all_classes == digit\n",
    "    digit_correct = np.sum((predictions == all_classes) & digit_mask)\n",
    "    digit_total = np.sum(digit_mask)\n",
    "    digit_acc = digit_correct / digit_total\n",
    "    print(f\"Digit {digit}: {digit_acc:.4f} ({digit_correct}/{digit_total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this practical, you have:\n",
    "\n",
    "1. **Learned transfer learning**: You used a model pre-trained on ImageNet (natural images) and adapted it to MNIST (handwritten digits)\n",
    "2. **Understood domain adaptation**: MNIST images are very different from ImageNet (grayscale, simple shapes vs. color, complex objects), yet transfer learning still works!\n",
    "3. **Trained efficiently**: By freezing pre-trained weights and training only the final layer, you trained the model in just a few minutes\n",
    "4. **Achieved good performance**: With only ~12,800 trainable parameters, the model likely achieved >90% accuracy\n",
    "\n",
    "### Extension ideas:\n",
    "\n",
    "Try modifying the code to:\n",
    "1. **Fine-tune more layers**: Unfreeze some earlier layers and train with a smaller learning rate\n",
    "2. **Add data augmentation**: Apply random rotations, translations to improve robustness\n",
    "3. **Compare architectures**: Try other small models used for classification\n",
    "4. **Use a different dataset**: Try Fashion-MNIST or CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2-idl (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
